= Inteligencia Artificial V - Random Forest


+*In[64]:*+
[source, ipython3]
----
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
----


+*In[65]:*+
[source, ipython3]
----
vinos = pd.read_csv('vino.csv')
vinos.head()
----


+*Out[65]:*+
----
[cols=",,,,,,,,,,,,,,",options="header",]
|=======================================================================
| |Alcohol |Malic acid |Ash |Alcalinity of ash |Magnesium |Total phenols
|Flavanoids |Nonflavanoid phenols |Proanthocyanins |Color intensity |Hue
|OD280/OD315 of diluted wines |Proline |Wine Type
|0 |14.23 |1.71 |2.43 |15.6 |127.0 |2.80 |3.06 |0.28 |2.29 |5.64 |1.04
|3.92 |1065.0 |One

|1 |13.20 |1.78 |2.14 |11.2 |100.0 |2.65 |2.76 |0.26 |1.28 |4.38 |1.05
|3.40 |1050.0 |One

|2 |13.16 |2.36 |2.67 |18.6 |101.0 |2.80 |3.24 |0.30 |2.81 |5.68 |1.03
|3.17 |1185.0 |One

|3 |14.37 |1.95 |2.50 |16.8 |113.0 |3.85 |3.49 |0.24 |2.18 |7.80 |0.86
|3.45 |1480.0 |One

|4 |13.24 |2.59 |2.87 |21.0 |118.0 |2.80 |2.69 |0.39 |1.82 |4.32 |1.04
|2.93 |735.0 |One
|=======================================================================
----


+*In[74]:*+
[source, ipython3]
----
x = vinos.drop('Wine Type', axis = 1)
y = vinos['Wine Type']
----


+*In[75]:*+
[source, ipython3]
----
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.3, random_state = 45) #El ultimo puede ser cualquiera
----


+*In[76]:*+
[source, ipython3]
----
from sklearn.ensemble import RandomForestClassifier #Bib necesaria para el RF
----


+*In[77]:*+
[source, ipython3]
----
ran_for = RandomForestClassifier(n_estimators = 100) #El numero de arboles
ran_for.fit(x_train,y_train)
predicciones = ran_for.predict(x_test) #Predecimos

from sklearn.metrics import classification_report, confusion_matrix
print( confusion_matrix(y_test,predicciones) )
print("\n")
print( classification_report(y_test,predicciones) )
----


+*Out[77]:*+
----
[[15  0  1]
 [ 0 19  1]
 [ 3  3 12]]


              precision    recall  f1-score   support

         One       0.83      0.94      0.88        16
       Three       0.86      0.95      0.90        20
         Two       0.86      0.67      0.75        18

    accuracy                           0.85        54
   macro avg       0.85      0.85      0.85        54
weighted avg       0.85      0.85      0.85        54

----

Mi codigo


+*In[78]:*+
[source, ipython3]
----
predicciones = predicciones.tolist() 
y_test = y_test.tolist()
----


+*In[79]:*+
[source, ipython3]
----
print( str(y_test.__len__()) + " : " + str(y_test.__len__()))
----


+*Out[79]:*+
----
54 : 54
----


+*In[73]:*+
[source, ipython3]
----
# Algoritmo para contar errores #
countTrue = 0
countFalse = 0
for i in range(0,54):
    if predicciones[i] == y_test[i]:
        countTrue += 1
    else:
        countFalse += 1
print("Acertados: "+str(countTrue)+"\nFallados: "+str(countFalse))
----


+*Out[73]:*+
----
Acertados: 54
Fallados: 0
----
