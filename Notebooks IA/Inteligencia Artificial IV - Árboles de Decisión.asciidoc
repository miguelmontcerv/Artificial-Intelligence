= Inteligencia Artificial IV - Árboles de Decisión


+*In[10]:*+
[source, ipython3]
----
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
----


+*In[14]:*+
[source, ipython3]
----
vinos = pd.read_csv('vino.csv')
vinos.head()
----


+*Out[14]:*+
----
[cols=",,,,,,,,,,,,,,",options="header",]
|=======================================================================
| |Alcohol |Malic acid |Ash |Alcalinity of ash |Magnesium |Total phenols
|Flavanoids |Nonflavanoid phenols |Proanthocyanins |Color intensity |Hue
|OD280/OD315 of diluted wines |Proline |Wine Type
|0 |14.23 |1.71 |2.43 |15.6 |127.0 |2.80 |3.06 |0.28 |2.29 |5.64 |1.04
|3.92 |1065.0 |One

|1 |13.20 |1.78 |2.14 |11.2 |100.0 |2.65 |2.76 |0.26 |1.28 |4.38 |1.05
|3.40 |1050.0 |One

|2 |13.16 |2.36 |2.67 |18.6 |101.0 |2.80 |3.24 |0.30 |2.81 |5.68 |1.03
|3.17 |1185.0 |One

|3 |14.37 |1.95 |2.50 |16.8 |113.0 |3.85 |3.49 |0.24 |2.18 |7.80 |0.86
|3.45 |1480.0 |One

|4 |13.24 |2.59 |2.87 |21.0 |118.0 |2.80 |2.69 |0.39 |1.82 |4.32 |1.04
|2.93 |735.0 |One
|=======================================================================
----


+*In[17]:*+
[source, ipython3]
----
vinos['Wine Type'].unique() #El tipo de valores
----


+*Out[17]:*+
----array(['One', 'Two', 'Three'], dtype=object)----


+*In[20]:*+
[source, ipython3]
----
vinos['Wine Type'].value_counts() #La cantidad de estos valores
----


+*Out[20]:*+
----Two      71
One      59
Three    48
Name: Wine Type, dtype: int64----


+*In[21]:*+
[source, ipython3]
----
x = vinos.drop('Wine Type', axis = 1)
x
----


+*Out[21]:*+
----
[cols=",,,,,,,,,,,,,",options="header",]
|=======================================================================
| |Alcohol |Malic acid |Ash |Alcalinity of ash |Magnesium |Total phenols
|Flavanoids |Nonflavanoid phenols |Proanthocyanins |Color intensity |Hue
|OD280/OD315 of diluted wines |Proline
|0 |14.23 |1.71 |2.43 |15.6 |127.0 |2.80 |3.06 |0.28 |2.29 |5.64 |1.04
|3.92 |1065.0

|1 |13.20 |1.78 |2.14 |11.2 |100.0 |2.65 |2.76 |0.26 |1.28 |4.38 |1.05
|3.40 |1050.0

|2 |13.16 |2.36 |2.67 |18.6 |101.0 |2.80 |3.24 |0.30 |2.81 |5.68 |1.03
|3.17 |1185.0

|3 |14.37 |1.95 |2.50 |16.8 |113.0 |3.85 |3.49 |0.24 |2.18 |7.80 |0.86
|3.45 |1480.0

|4 |13.24 |2.59 |2.87 |21.0 |118.0 |2.80 |2.69 |0.39 |1.82 |4.32 |1.04
|2.93 |735.0

|... |... |... |... |... |... |... |... |... |... |... |... |... |...

|173 |13.71 |5.65 |2.45 |20.5 |95.0 |1.68 |0.61 |0.52 |1.06 |7.70 |0.64
|1.74 |740.0

|174 |13.40 |3.91 |2.48 |23.0 |102.0 |1.80 |0.75 |0.43 |1.41 |7.30 |0.70
|1.56 |750.0

|175 |13.27 |4.28 |2.26 |20.0 |120.0 |1.59 |0.69 |0.43 |1.35 |10.20
|0.59 |1.56 |835.0

|176 |13.17 |2.59 |2.37 |20.0 |120.0 |1.65 |0.68 |0.53 |1.46 |9.30 |0.60
|1.62 |840.0

|177 |14.13 |4.10 |2.74 |24.5 |96.0 |2.05 |0.76 |0.56 |1.35 |9.20 |0.61
|1.60 |560.0
|=======================================================================

178 rows × 13 columns
----


+*In[24]:*+
[source, ipython3]
----
y = vinos['Wine Type']
y
----


+*Out[24]:*+
----0        One
1        One
2        One
3        One
4        One
       ...  
173    Three
174    Three
175    Three
176    Three
177    Three
Name: Wine Type, Length: 178, dtype: object----


+*In[25]:*+
[source, ipython3]
----
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.3, random_state = 45) #El ultimo puede ser cualquiera
----


+*In[26]:*+
[source, ipython3]
----
from sklearn.tree import DecisionTreeClassifier #Bibleoteca para los arboles
----


+*In[27]:*+
[source, ipython3]
----
arbol = DecisionTreeClassifier()
arbol.fit(x_train,y_train)
----


+*Out[27]:*+
----DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, presort='deprecated',
                       random_state=None, splitter='best')----


+*In[31]:*+
[source, ipython3]
----
predicciones = arbol.predict(x_test)
predicciones
----


+*Out[31]:*+
----array(['Three', 'Three', 'One', 'Two', 'Two', 'Two', 'Three', 'One',
       'One', 'Two', 'Two', 'One', 'One', 'Three', 'Three', 'Two', 'Two',
       'Three', 'Three', 'Three', 'Two', 'Two', 'One', 'Three', 'Three',
       'Three', 'One', 'Two', 'Three', 'Three', 'Three', 'Three', 'Three',
       'One', 'Two', 'Three', 'One', 'One', 'Two', 'One', 'Two', 'Two',
       'Two', 'Two', 'Two', 'Three', 'Three', 'Three', 'One', 'Two',
       'One', 'One', 'Three', 'One'], dtype=object)----


+*In[33]:*+
[source, ipython3]
----
from sklearn.metrics import classification_report, confusion_matrix
print( confusion_matrix(y_test,predicciones) )
----


+*Out[33]:*+
----
[[15  0  1]
 [ 0 19  1]
 [ 0  2 16]]
----


+*In[35]:*+
[source, ipython3]
----
print( classification_report(y_test,predicciones) )
----


+*Out[35]:*+
----
              precision    recall  f1-score   support

         One       1.00      0.94      0.97        16
       Three       0.90      0.95      0.93        20
         Two       0.89      0.89      0.89        18

    accuracy                           0.93        54
   macro avg       0.93      0.93      0.93        54
weighted avg       0.93      0.93      0.93        54

----

==== Mi codigo


+*In[36]:*+
[source, ipython3]
----
predicciones = predicciones.tolist() 
y_test = y_test.tolist()
----


+*In[42]:*+
[source, ipython3]
----
print( str(y_test.__len__()) + " : " + str(y_test.__len__()))
----


+*Out[42]:*+
----
54 : 54
----


+*In[43]:*+
[source, ipython3]
----
# Algoritmo para contar errores #
countTrue = 0
countFalse = 0
for i in range(0,54):
    if predicciones[i] == y_test[i]:
        countTrue += 1
    else:
        countFalse += 1
print("Acertados: "+str(countTrue)+"\nFallados: "+str(countFalse))
----


+*Out[43]:*+
----
Acertados: 50
Fallados: 4
----
